---
title: "Preprocessing Script for Summer School group 4"
author: "Rebecca Scarratt"
date: "2023-07-29"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
 
## Introduction

This is a script that will transform your data file from a mess of rows and columns that don't make any sense to a structure dataset.

in every R script, we start by loading the packages we will be using, defining the working directory and loading in the data. Make sure that the data file in the working directory. The working directory is the only folder that R can see when running this script , so it's important that all the files you will need are in that folder. It's also where the output files will save.

```{r load packages, working directory and data}
# we load the packages
library(dplyr)
library(ggplot2)
library(tidyverse)

# Set seed for reproducability
set.seed(1)

# set working directory
setwd("C:/Users/au672599/OneDrive - Aarhus Universitet/Documents/PhD Rebecca/Summer School/Online studies data")

# load in the data file. Note this only works with a .csv file. Here you need to change the name of the file.

data <- read.csv('survey_results_group4.csv')

# if it worked correctly, you should now see the dataframe 'data' appear in the Environment panel. You can click on it, to open it and check that it looks like your messy data file.
```

## Data reducing

Now that the data is loaded, we can start removing columns and rows that we don't need and making what we do need be more intuitive.
Of course, we don't change anything of what the cells contain, so it's important to check that we don't remove too much that would modify the data.
How exactly to do this step depends on the experiment.

```{r removing rows and columns}
# first, let's remove the rows we don't want. In the task column, it tells us what type of question/display we had. It saves information for all of them, but we are not always interested in all of them. This depends on each experiment but in your case, you are only interested in 'multi_choice', 'text_slider_response', 'audio_button', 'image_button' as that's where participants responses are stored. The rest can go.

data <- subset(data, task %in% c('multi_choice', 'text_slider_response', 'audio_button', 'image_button'))

# we want to keep columns 'run_id, stimulus and response'. The rest we can remove as it doesn't tell us anything important.

data<- data[c('run_id', 'stimulus', 'response')]

# now you can open data again to make sure you kept and deleted the right things. If there is a mistake, you can always load the data again and start again.

```

## Data reorganisation

Now that we have less rows and columns to deal with, we can make them be more intuitive.
At this point, it is sometimes helpful to draw out what type of table/dataframe you would want your data to look like in the end, and then work step by step to that goal.

```{r formating}
# let's rename each stimulus
data <- data %>%
  mutate(stimulus = case_when(
    stimulus == "<p>How familiar was this song to you ?</p>" ~ "familiarity",
    stimulus == "<p>Do you regard yourself as a visually creative person??</p>" ~ "creativity",
    stimulus == "<p>Do you regard yourself as a musician??</p>" ~ "musicianship",
    stimulus == "col.png" ~ "selected_colour",
    TRUE ~ stimulus  # If none of the conditions match, keep the original value
  ))

#now let's deal with the age and favourite colour info
data[data == ""] <- NA

demographic <- subset(data, is.na(stimulus))

demographic[c('1', '2', '3', '4', '5', '6', '7', '8', '9')] <- str_split_fixed(demographic$response, '"', 9)

demographic <- demographic[c('run_id', '2', '4', '6', '8')]

demographic %>% pivot_wider(names_from = c('2', '6'), values_from = c('4', '8')) -> demographic

colnames(demographic) <- c('run_id', 'age', 'favourite_colour')

data <- na.omit(data)

data <- merge(data, demographic, by ='run_id')

# Now we can check the number of people that answered and remove the non-complete answers.

# removing non-complete participants

data %>% count(run_id)
# as you can see in the output of this, every participant should have 3*4 +2 = 14 rows associated with them.

# here you can remove all the run_ids of participants who have less than 14 'counts'/rows.

data <- subset(data, !(run_id %in% c('2','6', '9', '10', '13')))

# we can do the above comand again to check we now have removed the non-completing participants

data %>% count(run_id)

# now let's remove the creativity and musicicanship questions for now

crea_mus <- subset(data, stimulus %in% c('creativity', 'musicianship'))

data <- subset(data, !(stimulus %in% c('creativity', 'musicianship')))

# We need to give information about the questions asked seperately from stimulus. Here you need to change the number of times the list of audio stimuli is repeated so that it matches the length of data. So if it is 132, we calculate 132/3=44, so we repeat it 44 times.

question_vector <- c('mystery', 'selected_colour', 'familiarity')
question_info <- data.frame(question = rep(question_vector, times = 44))

data <- cbind(data, question_info)


# now we want to indicate to each selected_colour and each familairity which song it belongs to
# Find the indices of every fifth item
indices <- seq(1, length(data$stimulus), by = 3)

# Repeat each fifth item five times
audio_info <- rep(data$stimulus[indices], each = 3)

data <- cbind(data, audio_info)

#remove unecessary column

data <- data[c('run_id', 'question', 'response', 'audio_info', 'age', 'favourite_colour')]

data %>% pivot_wider(names_from = question, values_from = response) -> data

# reorder columns

data <- data[c('run_id', 'audio_info', 'selected_colour', 'familiarity', 'mystery', 'age', 'favourite_colour')]

colnames(data)[2] = 'song'

# check that everything matches up before proceeding

# now we have finished the pre-processing of the data, we can save this final dataframe so we can continue the analyses and now have to always redo every preprocessing step

write.csv(data, 'survey_data_group4.csv')
```




